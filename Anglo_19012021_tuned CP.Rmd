---
title: "Anglo"
author: "Yi-Jhen"
date: "19 01 2021"
output: pdf_document
toc: true
top_depth: true
header-includes: 
- \usepackage{placeins}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r package, message=FALSE}
# Markdown 
library(knitr)
library(kableExtra)

# Data Analysis
library(dplyr)
library(naniar)
library(caret)
library(rpart)
library(rpart.plot)
library(rattle)
```

## Check the operation system
```{r system}
sessionInfo()
```

\newpage  

\FloatBarrier

## Versions of packages
```{r versions}
pkg <- tibble::tibble(
  Package = names(installed.packages()[,3]),
  Version = unname(installed.packages()[,3])
)

usePackages <- c("dplyr","naniar","caret","rpart","rpart.plot","rattle")
version <- dplyr::filter(pkg , Package %in% usePackages )
kable(version,caption = "Versions of packages")%>%
  kable_styling(latex_options =c("striped", "hold_position"))
```

## Data

```{r data }
dta <- read.csv("PV1.txt",sep="",header = FALSE)
nrow(dta)#sample size
colnames(dta) <- c("ST004D01T","IMMIG","ESCS","MOTIVAT","ANXTEST","EMOSUPS",
                   "BELONG","TEACHSUP","PVSCIE","ST016Q01NA","SENWT",
                   "IMMIG2","IMMIG3")
dta <- as.data.frame(dta[,c("ST004D01T","IMMIG","ESCS","MOTIVAT","ANXTEST",
                            "EMOSUPS","BELONG","TEACHSUP","PVSCIE","ST016Q01NA")])
dta <- dta%>%mutate_at(c("ST016Q01NA"),as.numeric)%>%replace_with_na_all(condition = ~.x==9999)
apply(dta,2,function(x) sum(is.na(x)/nrow(dta)))

dta <- dta%>%mutate(wb=cut(ST016Q01NA,
                                 quantile(ST016Q01NA, c(0, .25, .75, 1),na.rm=TRUE),
                                 labels = c('Low', 'Medium', 'High'),
                                 include.lowest = TRUE))

# Check the proportions of low, middle, and high well-being 
round(table(dta$wb,useNA = "always")/nrow(dta),digits = 2)#

# Selected only low and high well-being students 
dta_n <- dta%>%filter(wb=="Low"|wb=="High")%>%
  select(c("ST004D01T","IMMIG","ESCS","MOTIVAT","ANXTEST","EMOSUPS",
           "BELONG","TEACHSUP","PVSCIE","wb"))
nrow(dta_n) #sample size after including low and high well-being 

dta_n <- dta_n%>%mutate_at(c("ST004D01T","IMMIG"),as.factor)
dta_n$wb<- factor(dta_n$wb)

# 80% training data 
set.seed(1234);train <- sample(1:nrow(dta_n),floor(nrow(dta_n)*0.8),replace = FALSE)
training <- dta_n[train,]
testing <- dta_n[-train,]
```


## Model 0: Decision tree for training and testing data 
+ Baseline: default cp=0.01
```{r Model0}
#training
set.seed(1234);model <- rpart(wb~.,data=training,method = "class",na.action = na.omit)
Model0 <- summary(model)
model$cptable[which.min(model$cptable[,"xerror"]),"CP"]#show the cp values and find the small cross-validated error, which is 0.01
#variables are used in the tree , choosing cp based on the low xerror 
prune0 <- prune(model, cp = 0.01)
Pred0 <- predict(prune0,training,type="class")
acc0<- confusionMatrix(Pred0,training$wb)
acc0

#testing
PredT0 <- predict(prune0,testing,type="class")
accT0 <- confusionMatrix(PredT0,testing$wb)
accT0
```

\newpage  

\FloatBarrier

## Plot and important variables for the baseline model

```{r Model0plot}
rpart.plot(prune0,extra = 104,yesno=2)
Model0 $variable.importance
#importance variables were scaled to 100
barplot(t((Model0 $variable.importance/sum(Model0$variable.importance)*100)),horiz=TRUE,xlim = c(0,100))
```


## Model1: Decision tree for training and testing data 
+ Pruned model: let a tree fully grows(set cp=0), then find a smallest cross-validated error

```{r Model1}
# training
set.seed(1234);model1 <- rpart(wb~.,data=training,method = "class",na.action = na.omit,
                              control=rpart.control(cp=0))
# set seed to make results reproducible
Model1 <- summary(model1)
# show the cp values and find the small cross-validated error
plotcp(model1)
model1$cptable[which.min(model1$cptable[,"xerror"]),"CP"]
prune1 <- prune(model1, cp = 0.001930768)
Model1 <- summary(prune1)
#variables are used in the tree , choosing cp based on the low xerror 
Pred1 <- predict(prune1,training,type="class")
acc1<- confusionMatrix(Pred1,training$wb)
acc1

# testing
PredT1 <- predict(prune1,testing,type="class")
accT1 <- confusionMatrix(PredT1,testing$wb)
accT1
```


\newpage  

\FloatBarrier

## Plot and important variables for the tunned model

```{r Model1plot}
rpart.plot(prune1,extra = 104,yesno=2)
Model1 $variable.importance
#importance variables were scaled to 100
barplot(t((Model1$variable.importance/sum(Model1$variable.importance)*100)),horiz=TRUE,xlim = c(0,100))
```


## Model2: Decision tree for training and testing data 
+ Pruned model: 1+SD rule to tune the tree
+ CP=0.002689284

```{r Model2}

prune2 <- prune(model1, cp = 0.002689284)
Model2 <- summary(prune2)
#variables are used in the tree , choosing cp based on the low xerror 
Pred2 <- predict(prune2,training,type="class")
acc2<- confusionMatrix(Pred2,training$wb)
acc2

# testing
PredT2 <- predict(prune2,testing,type="class")
accT2 <- confusionMatrix(PredT2,testing$wb)
accT2
```


\newpage  

\FloatBarrier

## Plot and important variables for the tunned model

```{r}
rpart.plot(prune2,extra = 104,yesno=2)
Model2 $variable.importance
#importance variables were scaled to 100
barplot(t((Model2$variable.importance/sum(Model2$variable.importance)*100)),horiz=TRUE,xlim = c(0,100))
```
